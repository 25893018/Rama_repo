Storage in K8s:
===============
Understanding and creating persistent volumes
access modes for volumes
understanding of persistent volume claims
mounting persistent volume in pods
what are storage classes and dynamic volume provising?

Storage -Host Path:
================
store data in a specified directory on a kubernetis node where exactly
pod is created.

=====================
write one simple volume yaml file:
===================
vi volume.yaml

apiVersion: v1
kind: Pod
metadata:
name:my-pod
spec:

volumes:
- name: my-volume
hostPath:
path: /var/k8s

containers:
   restartPolicy: Never   
  - name: mybusybox
  image: busybox
  command: ['sh', 'echo learining k8's > /rama/k8s.txt && sleep 3600']
  
  volumeMounts:
  - name: my-volume
  mountPath: /rama
  
  
$  kubectl apply -f volume.yaml

here in your pod we have some data stored when your pod is deleted, automatially  you will loose here your data in k8s.txt also so to avoid this we can use volumes.

if we use volumes if pod is deleted still you can see your data in same path.


====================
  to login to your worker nodes:
  ===============
  $ gcloud compute instances list --configuration k8straining
  
  once you login take ip and run to login your node using in your terminal
  
  ssh rama@ipaddress

=======================
Role Authorization for user groups:
========================
https://www.youtube.com/watch?v=XGlm9grEsAo&list=PL7FZYPGA1pLxmICMjs7vHJWrKhq9vDUei&index=4

kubernetes authorization types:

node Authorization
ABAC Authorization  -> attribute based access control
RBAC Authorization  --> Role based access control >>IMP one
Web hook Authorization

if you want to give  permissions to the dev team member to give access to a pod 
then we can use RBAC to give permissions.
RBAC is to give  access to user as a simple example

Kind: Role --> will give permissions for user/any teams(dev,uat,prod) either delete, view , update ,create, get, list, watch.....;

if we wanted manage permissions , we can use role & role binding 
and for cluser level --> cluster role , cluster role binding.

kubectl get nodes 

roles.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: dev
  name: pod-reader
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["pods"]
  verbs: ["get", "watch", "list"]  --> indicates type of access.
  
  
  Role binding:
  
  apiVersion: rbac.authorization.k8s.io/v1
# This role binding allows "dev" to read pods in the "dev" namespace.
# You need to already have a Role named "pod-reader" in that namespace.
kind: RoleBinding
metadata:
  name: read-pods
  namespace: dev
subjects:
# You can specify more than one "subject"
- kind: User
  name: dev # "name" is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  # "roleRef" specifies the binding to a Role / ClusterRole
  kind: Role #this must be Role or ClusterRole
  name: pod-reader # this must match the name of the Role or ClusterRole you wish to bind to
  apiGroup: rbac.authorization.k8s.io
 ----------------------- 
  kubectl apply -f role.yaml 
  kubectl apply -f rolebinding.yaml
           
  kubectl get role --> to display role
  kubectl get ro  le -n dev 
  kubectl get rolebinding -n dev
  
  kubectl run pod1 --image nginx -n dev  --> to create a new pod in dev namespace but you will get error here becz you dont permissions to create in 
  
  check in role.yaml , you dont have permissions to create, you should use "create" in verbs to create pod in namespace in verbs.  
 
 after adding try 
  ===================================

 
============== 
managing applicaion configuration
=================
    - configuringEnv varaibles in apps
    - using  config maps for configuration
    - using screts for sensitive data in k8's.
managing container resources
monitoring container health with probes
building self-healing pods with restart policies
creating multi container pods

installing kubernetes dashboard:

kubectl get ns  --> namespaces
kubectl get deploy
kebectl get nodes
kubectl get pods 

insted executing all above these commonds , you can create dashboard using

kubectlproxey or kubectl port or ingress.

git URL: github.com/kubernetes/dashboard --all steps you can see it here

Install
To deploy Dashboard, execute following command:

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml

kubectl get deploy,svc  --defalut dashboard details give you
kubectl get deploy,svc -n kubernetes-dashboard


if you want to access your dashboard from outside /external(http)
you can use /go to github/docs/dashboard arguments and then take port and update your yaml file in your arguments sectin.

kubectl edit deploy kubernetes-dashboard -n kubernetes-dashboard

args:
- --insecure-port:9090
along with you need ot change 
port:9090
scheme:HTTP insted HTTPS

after yaml update you can see now new pod is creted and you want to see on your dashboard now

kubectl get svc -n kubernetes-dashboard

directly Cluster IP you cannot access from out side , but i want to acccess from outside with in the cluster , so i want to edit the service


kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard

then edit --> search type( by default it will be ClusterIP) 

change it to NodePort to access

targetport and port numbers will be 9090

now how to access dashboard 

kubectl get ns
kubectl get sa -n kubernetes-dashboard   -to see default service
(service account)

kubectl get rolebindings -n kubernetes-dashboard

to create a role to the serivice account to access dashbard

kubectl create rolebinding ramarolebinding --seriviceaccount kubernetes-dashboard:kubernetes-dashboard --clusterrole view -n kubernetes-dashboard --dry-run=client -o yaml

please note --dry-run=client -o yaml ( to view your file how it is going to create)

this is for only particular dashboard to access( only particular namespace)

kubectl create rolebinding ramarolebinding --seriviceaccount kubernetes-dashboard:kubernetes-dashboard --clusterrole view -n kubernetes-dashboard

else i want to access my entire cluster to access use this command

kubectl create clusterrolebinding ramarolebinding --seriviceaccount kubernetes-dashboard:kubernetes-dashboard --clusterrole view -n kubernetes-dashboard

role binding is nothing but a access to particular namespace or give access permissions to dashboard to show on web

Clusterrolebinding is nothing but a access to entire cluster namespaces to show on dashboard


  kubectl run pod1 --image nginx -n dev
  
  same like if i want to delete pod, still i dont have access as i didnt given type of access in roles.yaml...you can give "delete" in verbs to delete a pod
           
  kubectl delete pod pod1 -n dev  --> dev is a namespace
